{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84c23aac-d5da-45fa-9f4d-a56f5b689d60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%python\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit,countDistinct\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Stanislas Titanic ML version on Spark \") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "titanic_train_file_path=\"dbfs:/FileStore/train.csv\"\n",
    "titanic_df = spark.read.csv(titanic_train_file_path,header = 'True',inferSchema='True')\n",
    "\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f7d263a-7689-40fd-9fc0-be35c6998200",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of row: 891\n+--------------------------+\n|number of unique passenger|\n+--------------------------+\n|                       891|\n+--------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Compute the number of passenger and check if PassengerId are unique\n",
    "\n",
    "passengers_row = titanic_df.count()\n",
    "print('number of row: '+str(passengers_row)) #891.\n",
    "\n",
    "passengers_count=titanic_df.select(countDistinct('PassengerId').alias('number of unique passenger'))\n",
    "\n",
    "passengers_count.show() #891 id are unique\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85a53a0-3313-4df4-821e-13d948f7da31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUM UP :\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"SUM UP :\")\n",
    "titanic_df.describe().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74c5d01-f7ba-4fe2-b461-8ccf74738faa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF SCHEMA :\nroot\n |-- PassengerId: integer (nullable = true)\n |-- Survived: integer (nullable = true)\n |-- Pclass: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- SibSp: integer (nullable = true)\n |-- Parch: integer (nullable = true)\n |-- Ticket: string (nullable = true)\n |-- Fare: double (nullable = true)\n |-- Cabin: string (nullable = true)\n |-- Embarked: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "print(\"DF SCHEMA :\")\n",
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbcbf1cb-7101-4f48-b167-fb05789783a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+\n|Survived|Pclass|Embarked|\n+--------+------+--------+\n|       0|     3|       S|\n|       1|     1|       C|\n|       1|     3|       S|\n|       1|     1|       S|\n|       0|     3|       S|\n|       0|     3|       Q|\n|       0|     1|       S|\n|       0|     3|       S|\n|       1|     3|       S|\n|       1|     2|       C|\n|       1|     3|       S|\n|       1|     1|       S|\n|       0|     3|       S|\n|       0|     3|       S|\n|       0|     3|       S|\n|       1|     2|       S|\n|       0|     3|       Q|\n|       1|     2|       S|\n|       0|     3|       S|\n|       1|     3|       C|\n+--------+------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titanic_df.select(\"Survived\",\"Pclass\",\"Embarked\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82fe0704-4b9e-4f02-994d-458d2b7abf4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze survivor number\n+--------+-----+\n|Survived|count|\n+--------+-----+\n|       1|  342|\n|       0|  549|\n+--------+-----+\n\nSex Repartition\n+------+--------+-----+\n|   Sex|Survived|count|\n+------+--------+-----+\n|female|       1|  233|\n|female|       0|   81|\n|  male|       0|  468|\n|  male|       1|  109|\n+------+--------+-----+\n\nPclass repartition\n+------+--------+-----+\n|Pclass|Survived|count|\n+------+--------+-----+\n|     1|       0|   80|\n|     1|       1|  136|\n|     2|       1|   87|\n|     2|       0|   97|\n|     3|       1|  119|\n|     3|       0|  372|\n+------+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyze survivor number\")\n",
    "titanic_df.groupBy(\"Survived\").count().show() \n",
    "\n",
    "\n",
    "\n",
    "print(\"Sex Repartition\")\n",
    "titanic_df.groupBy(\"Sex\",\"Survived\").count().orderBy('Sex').orderBy('Sex').show()\n",
    "\n",
    "print('Pclass repartition')\n",
    "titanic_df.groupBy(\"Pclass\",\"Survived\").count().orderBy('Pclass').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bb2e833-7a69-46b7-965c-4ffb89e91c39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'PassengerId' has 0 null values.\nColumn 'Survived' has 0 null values.\nColumn 'Pclass' has 0 null values.\nColumn 'Name' has 0 null values.\nColumn 'Sex' has 0 null values.\nColumn 'Age' has 177 null values.\nColumn 'SibSp' has 0 null values.\nColumn 'Parch' has 0 null values.\nColumn 'Ticket' has 0 null values.\nColumn 'Fare' has 0 null values.\nColumn 'Cabin' has 687 null values.\nColumn 'Embarked' has 2 null values.\n"
     ]
    }
   ],
   "source": [
    "null_counts = [(column, titanic_df.where(titanic_df[column].isNull()).count()) for column in titanic_df.columns] #Count all null values for each feature \n",
    "\n",
    "for column, count in null_counts:\n",
    "    print(f\"Column '{column}' has {count} null values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cde6819a-273d-4e55-8fae-af51bc8f4b19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Initial|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr|\n|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|     Mr|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S| Master|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|     Mr|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q| Master|\n|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|     Mr|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs|\n|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|    Mrs|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\nonly showing top 20 rows\n\n+--------+\n| Initial|\n+--------+\n|     Don|\n|    Miss|\n|Countess|\n|     Col|\n|     Rev|\n|    Lady|\n|  Master|\n|     Mme|\n|    Capt|\n|      Mr|\n|      Dr|\n|     Mrs|\n|     Sir|\n|Jonkheer|\n|    Mlle|\n|   Major|\n|      Ms|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##########################################\n",
    "#                                        #\n",
    "#             Feature Engineering        #\n",
    "#                                        #\n",
    "##########################################\n",
    "\n",
    "\n",
    "#\n",
    "#             FIX Feature: AGE \n",
    "#\n",
    "\n",
    "titanic_df = titanic_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "\n",
    "titanic_df.show()\n",
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068725ec-d3c6-4297-8faf-53bc78bc8226",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n|Initial|\n+-------+\n|   Miss|\n|  Other|\n| Master|\n|     Mr|\n|    Mrs|\n+-------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])\n",
    "\n",
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de5b16e5-221b-4596-a880-af64f6210259",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Initial|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr|\n|          6|       0|     3|    Moran, Mr. James|  male|33.0|    0|    0|          330877| 8.4583| null|       Q|     Mr|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S| Master|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|     Mr|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q| Master|\n|         18|       1|     2|Williams, Mr. Cha...|  male|33.0|    0|    0|          244373|   13.0| null|       S|     Mr|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs|\n|         20|       1|     3|Masselmani, Mrs. ...|female|36.0|    0|    0|            2649|  7.225| null|       C|    Mrs|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))\n",
    "\n",
    "     \n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9640aeb3-aae7-4c6e-ac14-fe1c1589f9ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n|Embarked|count|\n+--------+-----+\n|       Q|   77|\n|    null|    2|\n|       C|  168|\n|       S|  644|\n+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#             FIX Feature: Embarked \n",
    "#\n",
    "\n",
    "\n",
    "titanic_df.groupBy(\"Embarked\").count().show()\n",
    "\n",
    "titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'}) #Because Majority of people are in S\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "545771f7-d4a4-40cb-a5c1-7a503532964f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.8958, 14.4542, 30.5]\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Initial|Fareband|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr|     1.0|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs|     4.0|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss|     2.0|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs|     4.0|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr|     2.0|\n|          6|       0|     3|    Moran, Mr. James|  male|33.0|    0|    0|          330877| 8.4583| null|       Q|     Mr|     2.0|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr|     4.0|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S| Master|     3.0|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs|     2.0|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs|     3.0|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss|     3.0|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss|     3.0|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr|     2.0|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|     Mr|     4.0|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss|     1.0|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs|     3.0|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q| Master|     3.0|\n|         18|       1|     2|Williams, Mr. Cha...|  male|33.0|    0|    0|          244373|   13.0| null|       S|     Mr|     2.0|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs|     3.0|\n|         20|       1|     3|Masselmani, Mrs. ...|female|36.0|    0|    0|            2649|  7.225| null|       C|    Mrs|     1.0|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#           REWORK FARE\n",
    "# \n",
    "\n",
    "#Create Fareband\n",
    "\n",
    "\n",
    "quantiles = titanic_df.approxQuantile(\"fare\", [0.25, 0.5, 0.75], 0.01)\n",
    "\n",
    "print(quantiles)\n",
    "\n",
    "titanic_df = titanic_df.withColumn(\"Fareband\",when((titanic_df[\"Fare\"] < quantiles[0]), 1).otherwise(titanic_df[\"Fare\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Fareband\",when((titanic_df[\"Fare\"] >= quantiles[0]) & (titanic_df[\"Fare\"] < quantiles[1]) , 2).otherwise(titanic_df[\"fareband\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Fareband\",when((titanic_df[\"Fare\"] >= quantiles[1]) & (titanic_df[\"Fare\"] < quantiles[2]) , 3).otherwise(titanic_df[\"fareband\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Fareband\",when((titanic_df[\"Fare\"] >= quantiles[2]) , 4).otherwise(titanic_df[\"fareband\"]))\n",
    "\n",
    "\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f9c90bb-45e5-49c3-aaac-82d1d7d2ef4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+--------+-----------+-----+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|Initial|Fareband|Family_Size|Alone|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+--------+-----------+-----+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|     Mr|     1.0|          1|    0|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|    Mrs|     4.0|          1|    0|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|   Miss|     2.0|          0|    1|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|    Mrs|     4.0|          1|    0|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|     Mr|     2.0|          0|    1|\n|          6|       0|     3|    Moran, Mr. James|  male|33.0|    0|    0|          330877| 8.4583|       Q|     Mr|     2.0|          0|    1|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|     Mr|     4.0|          0|    1|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S| Master|     3.0|          4|    0|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|    Mrs|     2.0|          2|    0|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|    Mrs|     3.0|          1|    0|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|   Miss|     3.0|          2|    0|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|   Miss|     3.0|          0|    1|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|     Mr|     2.0|          0|    1|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|     Mr|     4.0|          6|    0|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|   Miss|     1.0|          0|    1|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|    Mrs|     3.0|          0|    1|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q| Master|     3.0|          5|    0|\n|         18|       1|     2|Williams, Mr. Cha...|  male|33.0|    0|    0|          244373|   13.0|       S|     Mr|     2.0|          0|    1|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|    Mrs|     3.0|          1|    0|\n|         20|       1|     3|Masselmani, Mrs. ...|female|36.0|    0|    0|            2649|  7.225|       C|    Mrs|     1.0|          0|    1|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+--------+-----------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#\n",
    "#             DROP Feature: Cabin \n",
    "#\n",
    "\n",
    "titanic_df = titanic_df.drop(\"Cabin\") #too much null values, not exploitable\n",
    "\n",
    "#\n",
    "#            ADD Feature: Family Size\n",
    "#\n",
    "\n",
    "titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))\n",
    "\n",
    "#\n",
    "#            ADD Feature: Alone\n",
    "#\n",
    "titanic_df = titanic_df.withColumn('Alone',lit(0))\n",
    "titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))\n",
    "\n",
    "titanic_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bddabe67-f989-4784-be61-e005bae73441",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+\n|Survived|Pclass| Age|SibSp|Parch|   Fare|Fareband|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|\n+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+\n|       0|     3|22.0|    1|    0|   7.25|     1.0|          1|    0|      0.0|           0.0|          0.0|\n|       1|     1|38.0|    1|    0|71.2833|     4.0|          1|    0|      1.0|           1.0|          2.0|\n|       1|     3|26.0|    0|    0|  7.925|     2.0|          0|    1|      1.0|           0.0|          1.0|\n|       1|     1|35.0|    1|    0|   53.1|     4.0|          1|    0|      1.0|           0.0|          2.0|\n|       0|     3|35.0|    0|    0|   8.05|     2.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3|33.0|    0|    0| 8.4583|     2.0|          0|    1|      0.0|           2.0|          0.0|\n|       0|     1|54.0|    0|    0|51.8625|     4.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3| 2.0|    3|    1| 21.075|     3.0|          4|    0|      0.0|           0.0|          3.0|\n|       1|     3|27.0|    0|    2|11.1333|     2.0|          2|    0|      1.0|           0.0|          2.0|\n|       1|     2|14.0|    1|    0|30.0708|     3.0|          1|    0|      1.0|           1.0|          2.0|\n|       1|     3| 4.0|    1|    1|   16.7|     3.0|          2|    0|      1.0|           0.0|          1.0|\n|       1|     1|58.0|    0|    0|  26.55|     3.0|          0|    1|      1.0|           0.0|          1.0|\n|       0|     3|20.0|    0|    0|   8.05|     2.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3|39.0|    1|    5| 31.275|     4.0|          6|    0|      0.0|           0.0|          0.0|\n|       0|     3|14.0|    0|    0| 7.8542|     1.0|          0|    1|      1.0|           0.0|          1.0|\n|       1|     2|55.0|    0|    0|   16.0|     3.0|          0|    1|      1.0|           0.0|          2.0|\n|       0|     3| 2.0|    4|    1| 29.125|     3.0|          5|    0|      0.0|           2.0|          3.0|\n|       1|     2|33.0|    0|    0|   13.0|     2.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3|31.0|    1|    0|   18.0|     3.0|          1|    0|      1.0|           0.0|          2.0|\n|       1|     3|36.0|    0|    0|  7.225|     1.0|          0|    1|      1.0|           1.0|          2.0|\n+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#            ENCODE Features: Sex\",\"Embarked\",\"Initial\n",
    "#\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(titanic_df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "titanic_df = pipeline.fit(titanic_df).transform(titanic_df)\n",
    "\n",
    "#\n",
    "#            DROP Unused Features\n",
    "#\n",
    "\n",
    "titanic_df = titanic_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\")\n",
    "titanic_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "904c2aca-f581-4a09-a0e8-20e0274752c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+\n|Survived|Pclass| Age|SibSp|Parch|   Fare|Fareband|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|\n+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+\n|       0|     3|22.0|    1|    0|   7.25|     1.0|          1|    0|      0.0|           0.0|          0.0|\n|       1|     1|38.0|    1|    0|71.2833|     4.0|          1|    0|      1.0|           1.0|          2.0|\n|       1|     3|26.0|    0|    0|  7.925|     2.0|          0|    1|      1.0|           0.0|          1.0|\n|       1|     1|35.0|    1|    0|   53.1|     4.0|          1|    0|      1.0|           0.0|          2.0|\n|       0|     3|35.0|    0|    0|   8.05|     2.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3|33.0|    0|    0| 8.4583|     2.0|          0|    1|      0.0|           2.0|          0.0|\n|       0|     1|54.0|    0|    0|51.8625|     4.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3| 2.0|    3|    1| 21.075|     3.0|          4|    0|      0.0|           0.0|          3.0|\n|       1|     3|27.0|    0|    2|11.1333|     2.0|          2|    0|      1.0|           0.0|          2.0|\n|       1|     2|14.0|    1|    0|30.0708|     3.0|          1|    0|      1.0|           1.0|          2.0|\n|       1|     3| 4.0|    1|    1|   16.7|     3.0|          2|    0|      1.0|           0.0|          1.0|\n|       1|     1|58.0|    0|    0|  26.55|     3.0|          0|    1|      1.0|           0.0|          1.0|\n|       0|     3|20.0|    0|    0|   8.05|     2.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3|39.0|    1|    5| 31.275|     4.0|          6|    0|      0.0|           0.0|          0.0|\n|       0|     3|14.0|    0|    0| 7.8542|     1.0|          0|    1|      1.0|           0.0|          1.0|\n|       1|     2|55.0|    0|    0|   16.0|     3.0|          0|    1|      1.0|           0.0|          2.0|\n|       0|     3| 2.0|    4|    1| 29.125|     3.0|          5|    0|      0.0|           2.0|          3.0|\n|       1|     2|33.0|    0|    0|   13.0|     2.0|          0|    1|      0.0|           0.0|          0.0|\n|       0|     3|31.0|    1|    0|   18.0|     3.0|          1|    0|      1.0|           0.0|          2.0|\n|       1|     3|36.0|    0|    0|  7.225|     1.0|          0|    1|      1.0|           1.0|          2.0|\n+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1949982-0dc6-4a23-bcff-9060c15b7ac3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+--------------------+\n|Survived|Pclass| Age|SibSp|Parch|   Fare|Fareband|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|            features|\n+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+--------------------+\n|       0|     3|22.0|    1|    0|   7.25|     1.0|          1|    0|      0.0|           0.0|          0.0|(11,[0,1,2,4,5,6]...|\n|       1|     1|38.0|    1|    0|71.2833|     4.0|          1|    0|      1.0|           1.0|          2.0|[1.0,38.0,1.0,0.0...|\n|       1|     3|26.0|    0|    0|  7.925|     2.0|          0|    1|      1.0|           0.0|          1.0|[3.0,26.0,0.0,0.0...|\n|       1|     1|35.0|    1|    0|   53.1|     4.0|          1|    0|      1.0|           0.0|          2.0|[1.0,35.0,1.0,0.0...|\n|       0|     3|35.0|    0|    0|   8.05|     2.0|          0|    1|      0.0|           0.0|          0.0|(11,[0,1,4,5,7],[...|\n|       0|     3|33.0|    0|    0| 8.4583|     2.0|          0|    1|      0.0|           2.0|          0.0|(11,[0,1,4,5,7,9]...|\n|       0|     1|54.0|    0|    0|51.8625|     4.0|          0|    1|      0.0|           0.0|          0.0|(11,[0,1,4,5,7],[...|\n|       0|     3| 2.0|    3|    1| 21.075|     3.0|          4|    0|      0.0|           0.0|          3.0|[3.0,2.0,3.0,1.0,...|\n|       1|     3|27.0|    0|    2|11.1333|     2.0|          2|    0|      1.0|           0.0|          2.0|[3.0,27.0,0.0,2.0...|\n|       1|     2|14.0|    1|    0|30.0708|     3.0|          1|    0|      1.0|           1.0|          2.0|[2.0,14.0,1.0,0.0...|\n|       1|     3| 4.0|    1|    1|   16.7|     3.0|          2|    0|      1.0|           0.0|          1.0|[3.0,4.0,1.0,1.0,...|\n|       1|     1|58.0|    0|    0|  26.55|     3.0|          0|    1|      1.0|           0.0|          1.0|[1.0,58.0,0.0,0.0...|\n|       0|     3|20.0|    0|    0|   8.05|     2.0|          0|    1|      0.0|           0.0|          0.0|(11,[0,1,4,5,7],[...|\n|       0|     3|39.0|    1|    5| 31.275|     4.0|          6|    0|      0.0|           0.0|          0.0|[3.0,39.0,1.0,5.0...|\n|       0|     3|14.0|    0|    0| 7.8542|     1.0|          0|    1|      1.0|           0.0|          1.0|[3.0,14.0,0.0,0.0...|\n|       1|     2|55.0|    0|    0|   16.0|     3.0|          0|    1|      1.0|           0.0|          2.0|[2.0,55.0,0.0,0.0...|\n|       0|     3| 2.0|    4|    1| 29.125|     3.0|          5|    0|      0.0|           2.0|          3.0|[3.0,2.0,4.0,1.0,...|\n|       1|     2|33.0|    0|    0|   13.0|     2.0|          0|    1|      0.0|           0.0|          0.0|(11,[0,1,4,5,7],[...|\n|       0|     3|31.0|    1|    0|   18.0|     3.0|          1|    0|      1.0|           0.0|          2.0|[3.0,31.0,1.0,0.0...|\n|       1|     3|36.0|    0|    0|  7.225|     1.0|          0|    1|      1.0|           1.0|          2.0|[3.0,36.0,0.0,0.0...|\n+--------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+-------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#            Vectorize data\n",
    "#\n",
    "\n",
    "\n",
    "feature = VectorAssembler(inputCols=titanic_df.columns[1:],outputCol=\"features\")\n",
    "feature_vector= feature.transform(titanic_df)\n",
    "\n",
    "feature_vector.show()\n",
    "\n",
    "#\n",
    "#            Vectorize data\n",
    "#\n",
    "\n",
    "(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb013f9b-006d-463b-a1ad-e12e3b4ce602",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n|prediction|Survived|            features|\n+----------+--------+--------------------+\n|       1.0|       0|(11,[0,1,4,5,7,9]...|\n|       1.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,5,7],[1....|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       1.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       1.0|       0|(11,[0,1,3,4,5,6]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|[1.0,58.0,0.0,2.0...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|[2.0,19.0,1.0,1.0...|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of LogisticRegression is = 0.771277\nTest Error of LogisticRegression = 0.228723 \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#            Logistic Regression\n",
    "#\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "#Training algo\n",
    "lrModel = lr.fit(trainingData)\n",
    "lr_prediction = lrModel.transform(testData)\n",
    "lr_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "\n",
    "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
    "print(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\n",
    "print(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5852f8cf-db76-4f39-9e91-214ec678d8b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n|prediction|Survived|            features|\n+----------+--------+--------------------+\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       1.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       1.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,5,7],[1....|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,3,4,5,6]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|[1.0,58.0,0.0,2.0...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|[2.0,19.0,1.0,1.0...|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of DecisionTreeClassifier is = 0.819149\nTest Error of DecisionTreeClassifier = 0.180851 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(trainingData)\n",
    "dt_prediction = dt_model.transform(testData)\n",
    "dt_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "\n",
    "dt_accuracy = evaluator.evaluate(dt_prediction)\n",
    "print(\"Accuracy of DecisionTreeClassifier is = %g\"% (dt_accuracy))\n",
    "print(\"Test Error of DecisionTreeClassifier = %g \" % (1.0 - dt_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "817b0478-5daf-4ce6-bb6b-2e79c02e0621",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n|prediction|Survived|            features|\n+----------+--------+--------------------+\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,5,7],[1....|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,3,4,5,6]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|[1.0,58.0,0.0,2.0...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|[2.0,19.0,1.0,1.0...|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of RandomForestClassifier is = 0.808511\nTest Error of RandomForestClassifier  = 0.191489 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(trainingData)\n",
    "rf_prediction = rf_model.transform(testData)\n",
    "rf_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
    "print(\"Accuracy of RandomForestClassifier is = %g\"% (rf_accuracy))\n",
    "print(\"Test Error of RandomForestClassifier  = %g \" % (1.0 - rf_accuracy))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fca448cc-a9fe-4d70-b5cc-0f303cce3e3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n|prediction|Survived|            features|\n+----------+--------+--------------------+\n|       1.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       1.0|       0|(11,[0,1,4,5,7],[...|\n|       1.0|       0|(11,[0,1,2,4,5,6]...|\n|       1.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,5,7],[1....|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,3,4,5,6]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|[1.0,58.0,0.0,2.0...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|[2.0,19.0,1.0,1.0...|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of Gradient-boosted tree classifie is = 0.803191\nTest Error of Gradient-boosted tree classifie 0.196809\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\",maxIter=10)\n",
    "gbt_model = gbt.fit(trainingData)\n",
    "gbt_prediction = gbt_model.transform(testData)\n",
    "gbt_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "\n",
    "gbt_accuracy = evaluator.evaluate(gbt_prediction)\n",
    "print(\"Accuracy of Gradient-boosted tree classifie is = %g\"% (gbt_accuracy))\n",
    "print(\"Test Error of Gradient-boosted tree classifie %g\"% (1.0 - gbt_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f830a1a8-739a-4176-a7a6-fa0fbc0978e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n|prediction|Survived|            features|\n+----------+--------+--------------------+\n|       1.0|       0|(11,[0,1,4,5,7,9]...|\n|       1.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       1.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       1.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,5,7],[1....|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       1.0|       0|(11,[0,1,4,5,7],[...|\n|       1.0|       0|(11,[0,1,4,5,7],[...|\n|       1.0|       0|(11,[0,1,2,4,5,6]...|\n|       1.0|       0|(11,[0,1,3,4,5,6]...|\n|       1.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       1.0|       0|[1.0,58.0,0.0,2.0...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       1.0|       0|[2.0,19.0,1.0,1.0...|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of NaiveBayes is  = 0.739362\nTest Error of NaiveBayes  = 0.260638 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "nb_model = nb.fit(trainingData)\n",
    "nb_prediction = nb_model.transform(testData)\n",
    "nb_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "\n",
    "nb_accuracy = evaluator.evaluate(nb_prediction)\n",
    "print(\"Accuracy of NaiveBayes is  = %g\"% (nb_accuracy))\n",
    "print(\"Test Error of NaiveBayes  = %g \" % (1.0 - nb_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12426219-1d0b-4c9a-9976-4244c4440c87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n|prediction|Survived|            features|\n+----------+--------+--------------------+\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,5,7],[1....|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,3,4,5,6]...|\n|       0.0|       0|(11,[0,1,2,4,5,6]...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|[1.0,58.0,0.0,2.0...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7],[...|\n|       0.0|       0|(11,[0,1,4,5,7,9]...|\n|       0.0|       0|[2.0,19.0,1.0,1.0...|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of Support Vector Machine is = 0.808511\nTest Error of Support Vector Machine = 0.191489 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "svm = LinearSVC(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "svm_model = svm.fit(trainingData)\n",
    "svm_prediction = svm_model.transform(testData)\n",
    "svm_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "\n",
    "svm_accuracy = evaluator.evaluate(svm_prediction)\n",
    "print(\"Accuracy of Support Vector Machine is = %g\"% (svm_accuracy))\n",
    "print(\"Test Error of Support Vector Machine = %g \" % (1.0 - svm_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Titanic",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
